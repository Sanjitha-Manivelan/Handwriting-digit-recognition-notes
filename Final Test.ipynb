{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 44s 46ms/step - loss: 0.4107 - accuracy: 0.8684\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.0520 - accuracy: 0.9835\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 35s 37ms/step - loss: 0.0339 - accuracy: 0.9889\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.0247 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 37s 40ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0332 - accuracy: 0.9898\n",
      "0.989799976348877\n"
     ]
    }
   ],
   "source": [
    "# I'm importing the libraries and loading the dataset\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# I'm training the images and testing the labels and setting it equal to mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#I'm defining the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#Now I'm reshaping with the format [samples][width][height][channels]\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "#I'm compiling the optimizer, loss, and metrics\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#I'm fitting the model with the train_images and train_labels\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "#I'm testing the loss and accuracy by making the model evaluate the tes_images and labels\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "#I'm testing the accuracy\n",
    "print(test_acc)\n",
    "\n",
    "#I'm saving the model as mnist.h5\n",
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n",
      "172 220 776 724\n"
     ]
    }
   ],
   "source": [
    "# I started by importing the libraries\n",
    "from tkinter import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "from keras.models import load_model\n",
    "import webbrowser\n",
    "\n",
    "# I'm using Module 1 for the backend but the saved model is Module 2 for recognizing the digits\n",
    "model = load_model('mnist.h5')\n",
    "image_folder = \"img/\"\n",
    "\n",
    "# I'm initializing by creating a window and giving the title Handwritten Digit Recognition\n",
    "root = Tk()\n",
    "root.resizable(0, 0)\n",
    "root.title(\"Handwritten Digit Recognition\")\n",
    "\n",
    "lastx, lasty = None, None\n",
    "image_number = 0\n",
    "\n",
    "# I created the drawing area so users can draw the numbers\n",
    "cv = Canvas(root, width=600, height=500, bg='white')\n",
    "cv.grid(row=0, column=0, pady=2, sticky=NSEW, columnspan=2)\n",
    "\n",
    "# I'm clearing the drawing area when the users clicks clear output button\n",
    "def clear_widget():\n",
    "    global cv\n",
    "    cv.delete('all')\n",
    "\n",
    "# the draw and activate functions lets the user draw digits\n",
    "def draw_lines(event):\n",
    "    global lastx, lasty\n",
    "    x, y = event.x, event.y\n",
    "    cv.create_line((lastx, lasty, x, y), width=8, fill='black', capstyle=ROUND, smooth=TRUE, splinesteps=12)\n",
    "    lastx, lasty = x, y\n",
    "\n",
    "\n",
    "def activate_event(event):\n",
    "    global lastx, lasty\n",
    "    cv.bind('<B1-Motion>', draw_lines)\n",
    "    lastx, lasty = event.x, event.y\n",
    "\n",
    "\n",
    "cv.bind('<Button-1>', activate_event)\n",
    "\n",
    "# the recognize function predicts the digits that the user draws on the drawing area\n",
    "def Recognize_Digit():\n",
    "    global image_number\n",
    "    filename = f'img_{image_number}.png'\n",
    "    widget = cv\n",
    "\n",
    "    x = root.winfo_rootx() + widget.winfo_rootx()\n",
    "    y = root.winfo_rooty() + widget.winfo_rooty()\n",
    "    x1 = x + widget.winfo_width()\n",
    "    y1 = y + widget.winfo_height()\n",
    "    print(x, y, x1, y1)\n",
    "    \n",
    "    # I'm getting the image and saving it\n",
    "    ImageGrab.grab().crop((x, y, x1, y1)).save(image_folder + filename)\n",
    "\n",
    "    image = cv2.imread(image_folder + filename, cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    ret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    contours = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # I'm making a rectangle box around each curve\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "\n",
    "        # Then cropping out the digit from the image to the contours in the for loop\n",
    "        digit = th[y:y + h, x:x + w]\n",
    "\n",
    "        # Then I'm resizing the digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (18, 18))\n",
    "\n",
    "        # and padding the digit with 5 pixels to produce the image\n",
    "        padded_digit = np.pad(resized_digit, ((5, 5), (5, 5)), \"constant\", constant_values=0)\n",
    "\n",
    "        digit = padded_digit.reshape(1, 28, 28, 1)\n",
    "        digit = digit / 255.0\n",
    "\n",
    "        pred = model.predict([digit])[0]\n",
    "        final_pred = np.argmax(pred)\n",
    "\n",
    "        data = str(final_pred) + ' ' + str(int(max(pred) * 100)) + '%'\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 0.5\n",
    "        color = (255, 0, 0)\n",
    "        thickness = 1\n",
    "        cv2.putText(image, data, (x, y - 5), font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Predictions', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "# and then these are the buttons and the height, width, text and alignment of the buttons  \n",
    "btn_save = Button(text='Recognize Digits',width=15, height=3, command=Recognize_Digit)\n",
    "btn_save.grid(row=2, column=0, pady=1, padx=1)\n",
    "button_clear = Button(text='Clear Output',width=15, height=3, command=clear_widget)\n",
    "button_clear.grid(row=2, column=1, pady=1, padx=1)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
